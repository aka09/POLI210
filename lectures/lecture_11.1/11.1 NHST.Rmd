---
title: 'POLI210: Political Science Research Methods'
subtitle: "Lecture 11.2: Null Hypothesis Significance Testing"
date: "November 4th, 2021"
author: "Olivier Bergeron-Boutin"
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \usepackage{fontspec}
  - \usepackage{animate}
  - \usepackage{xmpmulti}
  - \usepackage{caption}
  - \setsansfont[BoldFont={FiraSans-Bold.ttf}]{FiraSans-Light.ttf}
  - \setmonofont{FiraMono-Regular.ttf}
  - \usepackage{color}
  - \definecolor{mygreen}{HTML}{008000}
output: 
  beamer_presentation:
    keep_tex: yes
    citation_package: biblatex
    theme: "metropolis"
    highlight: zenburn
    latex_engine: xelatex
classoption: t
urlcolor: blue
bibliography: ../210lectures_bib.bib
biblio-style: authoryear
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(fig.height = 6, fig.width = 10, 
                      message = FALSE, warning = FALSE,
                      out.width = '75%')
```

```{r customtheme,echo=FALSE}
# taken from Andrew Heiss' website
library(ggtext)
theme_custom <- function(){
  theme_minimal(base_size = 19,
           base_family = "Fira Sans") %+replace%
  theme(legend.position = "none",
        panel.grid.minor = element_blank(),
        plot.title = element_markdown(face = "bold", size = rel(1.7)),
        plot.subtitle = element_markdown(face = "plain", size = rel(1.3)),
        axis.title = element_text(face = "bold"),
        axis.title.x = element_text(margin = margin(t = 10), hjust = 0),
        axis.title.y = element_text(margin = margin(r = 10), hjust = 1, angle = 90))
}
```

## Boring admin stuff

- Problem set 4 will be posted today; **mandatory**
- Due dates:
  - Problem set 4: December 2nd, 11:59PM
  - Quiz 2: November 30th to December 4th
  - Group project: December 6th, 11:59PM
- Group project: you should find your teams ASAP
- I post interesting articles on MyCourses 
  
## Final project

- 1500 words
- Teams of four
- Pick one article out of 5 and critique it

## Articles to choose from

\footnotesize

```{r,echo=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
tribble(
  ~Article, ~Authors, ~`Substantive content`, ~`Methodology`,
  "The Signs of Deconsolidation", 
  "Roberto Stefan Foa and Yascha Mounk", 
  "Attitudes toward democracy in advanced democracies", 
  "Quantitative analysis of survey data",
  "The Great Divide: Literacy, Nationalism, and the Communist Collapse",
  "Keith Darden and Anna Grzymala-Busse",
  "Explaining cross-country variation in the success of communist parties in post-communist countries", 
  "Cross-country regression",
  "Conceptual Models and the Cuban Missile Crisis",
  "Graham T. Allison",
  "Analysis of the Cuban Missile Crisis and foreign affairs decision-making",
  "Case study using historical evidence",
  "Sources of Authoritarian Responsiveness: A Field Experiment in China",
  "Jidong Chen, Jennifer Pan, and Yiqing Xu",
  "What motivates government officials in an authoritarian state to be responsive to public demands?",
  "Field experiment in China",
  "Democracy, Autocracy, and Revolution in
Post-Soviet Eurasia",
"Henry E. Hale",
"The success or failure of transitions to democracy in post-communist Eurasia",
"Comparative analysis"
) %>% 
  knitr::kable(booktabs = TRUE) %>% 
  kable_styling(latex_options = "hold_position",
                font_size = 6) %>% 
  column_spec(1, width = "12em") %>% 
  column_spec(2, width = "8em") %>% 
  column_spec(3, width = "14em") %>% 
  column_spec(4, width = "9em") %>% 
  row_spec(0, bold = TRUE) %>% 
  row_spec(1:4, hline_after = TRUE)
```
  
## Exploration of midterm data 

```{r,echo=FALSE,out.width='100%',fig.height=7,fig.width=10}
library(tidyverse)
library(readr)
library(stringr)
library(ggplot2)
library(extrafont)
library(viridis)
library(ggpubr)
midterm <- read_csv("midterm/Midterm - Attempt Details.csv")

# taken from Andrew Heiss' website
library(ggtext)
theme_custom <- function(){
  theme_minimal(base_size = 19,
                base_family = "Fira Sans") %+replace%
    theme(legend.position = "none",
          panel.grid.minor = element_blank(),
          plot.title = element_markdown(face = "bold", size = rel(1.7)),
          plot.subtitle = element_markdown(face = "plain", size = rel(1.3)),
          axis.title = element_text(face = "bold"),
          axis.title.x = element_text(margin = margin(t = 10), hjust = 0),
          axis.title.y = element_text(margin = margin(r = 10), hjust = 1, angle = 90))
}

# important midterm answers
midterm <- midterm %>% 
  mutate(word_count = str_count(Answer, "\\w+"),
         q_type = ifelse(`Q #` %in% c(1, 2), "Essay", "Medium-length")) %>% 
  rename(question = `Q #`)

# plotting distribution of number of words per question
essay_plot <- ggplot(filter(midterm, question %in% 1:2),
       aes(x = word_count, y = factor(question))) +
  geom_violin(aes(fill = factor(question))) +
  geom_boxplot(width = 0.15, col = "grey", alpha = 0.4) +
  theme_bw(base_size = 13) +
  scale_x_continuous(breaks = seq(0, 1400, 200)) +
  scale_fill_manual(values = viridis(7)[1:2]) +
  labs(y = "Question",
       x = "Number of words") +
  guides(fill = "none") +
  theme_custom()

medium_plot <- ggplot(filter(midterm, question %in% 3:7), 
       aes(x = word_count, y = factor(question))) +
  geom_violin(aes(fill = factor(question))) +
  geom_boxplot(width = 0.15, col = "grey", alpha = 0.4) +
  theme_bw(base_size = 13) +
  scale_x_continuous(breaks = seq(0, 1400, 200)) +
  scale_fill_manual(values = viridis(7)[3:7]) +
  labs(x = "",
       y = "Question") +
  theme_custom()

ggarrange(medium_plot, essay_plot, nrow = 2,
          heights = c(1, 0.7),
          labels = c("Medium-length answers", "Essay answers"))
```

## Exploration of midterm data

```{r,echo=FALSE,out.width='100%',fig.height=7,fig.width=10}
library(tidytext)

# See here: https://rpubs.com/andrew-donnelly/589746

# a dataset at the word level for Q1
q1_words <- midterm %>%  
  unnest_tokens(word, Answer)

midterm_words_counts <- midterm %>%
  unnest_tokens(word, Answer) %>%
  count(question, word, sort = TRUE) 

total_words <- midterm_words_counts %>%
  group_by(question) %>% 
  summarize(total = sum(n))

midterm_words_counts <- left_join(midterm_words_counts, total_words)

midterms_tf_idf <- midterm_words_counts %>%             # Calculates tf-idf
  bind_tf_idf(word, question, n)


midterms_tf_idf %>%
  arrange(-tf_idf) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(question) %>% 
  top_n(5) %>% 
  filter(question != 7) %>% 
  ggplot(aes(x = word, y = tf_idf, fill = factor(question))) +
  geom_col(show.legend = FALSE) +
  labs(x = "", y = "Distinctiveness") +
  facet_wrap(~question, scales = "free",
             ncol = 2) +
  coord_flip() +
  theme_custom() +
  scale_fill_viridis_d() +
  labs(title = "Most distinctive words in each question")
```



## When do you believe me? 

Let's suppose that after the midterm, I tell you that the mean grade is 73 

- You suspect that I'm lying, for some reason...
- But don't want to call me out unless you're quite sure
- You ask a colleague in lab about their grade...
  - Then another, and another, and another...
- When do you have enough evidence to call me out? 

\pause
  
## Meeting students 

\centering

```{r,echo=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
hyp_grades <- tribble(~`Student #`, ~Grade,
       "1", 63,
       "2", 67,
       "3", 71,
       "4", 56,
       "5", 77,
       "6", 47,
       "7", 55)
kbl(hyp_grades[1,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## Meeting students 

\centering

```{r,echo=FALSE}
kbl(hyp_grades[1:2,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## Meeting students 

\centering

```{r,echo=FALSE}
kbl(hyp_grades[1:3,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## Meeting students 

\centering

```{r,echo=FALSE}
kbl(hyp_grades[1:4,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## Meeting students 

\centering

```{r,echo=FALSE}
kbl(hyp_grades[1:5,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## Meeting students 

\centering

```{r,echo=FALSE}
kbl(hyp_grades[1:6,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab")
```

Do you call me a liar? 

## The null hypothesis

The setup:

- We set a **null hypothesis**, also referred to as $H_0$
  - The null hypothesis is our reference point -- it is arbitrary!
  - It's a sort of statistical "strawman" 
- We then set an **alternative hypothesis**, or $H_1$
  - If the null is not true, then the alternative hypothesis must be true
- We start from the premise that the null hypothesis is true
  - The key question: *How surprised are you to see the data that you have, if the null hypothesis is true?*
  - Evidence is inconsistent with the null $\leadsto$ reject the null
  - Evidence is not inconsistent with the null $\leadsto$ fail to reject the null
- This is the framework of **hypothesis testing**
  - Start from the null
  - Think about what the data should look like, if the null were true
  - Analyze the data; reject/fail to reject the null
  
## The null hypothesis in our example

What was the null hypothesis in the example above? \pause

- $H_0$: $\mu_{exam} = 73$

What was the alternative hypothesis? \pause

- $H_1$: $\mu_{exam} \neq 73$ (non-directional hypothesis)
- $H_1$: $\mu_{exam} > 73$ (directional hypothesis)
- $H_1$: $\mu_{exam} < 73$ (directional hypothesis) \pause

## Hypothesis testing in our example

Assume that the null is true -- i.e. the true mean is 73

- What do you expect to see when talking to your peers? \pause
  - You expect to see have a sample mean of roughly 73!
  - It might be 71, it might be 75
    - Central limit theorem: the sampling distribution is normal and centered on the true population parameter 
  - But you would be surprised to talk to 20 random students and learn that their mean grade is 59
  - The data would be *inconsistent with the null hypothesis*
  - At some point, the data is *so inconsistent with the null hypothesis* that we are comfortable rejecting it 
    - How much we need to see before rejecting the null depends on the confidence level that we set
    
## Sampling distributions 

If the midterm average really is 73, the sampling distribution should look like this:

```{r,echo=FALSE,out.width='100%'}
library(ggtext)
library(extrafont)
set.seed(1031)
data.frame(student_grade = rnorm(200, mean = 73, sd = 3)) %>% 
  ggplot(aes(x = student_grade)) +
  geom_histogram(fill = "steelblue", col = "black") +
  labs(x = "Mean grade in any given sample",
       y = "Number of samples") +
  theme_custom() 
```

## Sampling distributions 

I can also show this using a density plot:

```{r,echo=FALSE,fig.width='100%'}
set.seed(1031)
data.frame(student_grade = rnorm(200, mean = 73, sd = 3)) %>% 
  ggplot(aes(x = student_grade)) +
  geom_density(col = "steel blue", size = 2) +
  theme_custom() +
  labs(x = "Mean grade in any given sample",
       y = "Density") +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_label(aes(x = 72, y = 0.03), label = expression(H[0]*":"*mu*"=73"), size = 5, parse = T)
```

## Sampling distributions with different SD

My sampling distribution may have a different standard deviation: 

```{r,echo=FALSE,out.width='100%'}
set.seed(1031)
data.frame(`sd_3` = rnorm(200, mean = 73, sd = 3),
           `sd_1` = rnorm(200, mean = 73, sd = 2),
           `sd_4` = rnorm(200, mean = 73, sd = 4)) %>% 
  gather() %>% 
  ggplot(aes(x = value, col = key)) +
  geom_density(size = 2) +
  scale_color_viridis_d() +
  theme_custom() %+replace%
  theme(legend.position = "bottom") +
  labs(x = "Mean grade in any given sample",
       y = "Density")
```

## The sampling distribution and hypothesis

Whatever the particular SD of sampling distribution...

- It should approximate a normal distribution and be centered on the true parameter
- The key feature of a normal distribution:
  - About 68.4% of the data is within 1SD of the mean
  - About 95% of the data is within 2SD of the mean
  - About 99.7% of the data is within 3SD of the mean
- Therefore, if the null is true, I am...
  - Not surprised to observe a sample statistic that's 1SD away from the null
  - Surprised to observe a sample statistic that's 2 SDs away from the null
  - Very surprised to observe a sample statistic that is 3 SDs away from the null
  
## What does my sampling distribution looks like?

Remember that, in practice, we only draw a single sample

- We *do not* observe the sampling distribution
- But, the sampling distribution has 2 properties:
  - The mean
    - We will assume that the mean is equal to whatever the null hypothesis indicates
  - Standard deviation, for which we have a good guess: 
    - $\hat{SE} = \dfrac{\hat{\sigma}}{\sqrt{n}}$
- With this in mind, we have a good idea of what the sampling distribution *should look like* if the null were true
  - And therefore we know how unlikely it is to have drawn the sample that we drew
  
## A hypothetical sampling distribution 

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(60,73)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(73, 86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## A hypothetical sampling distribution 

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(60,67)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(67, 79)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(79,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 65, y = 0.03,
           label = "Surprised to see this!", col = "#00998a") +
  annotate(geom = "segment", 
           x = 65, xend = 65, 
           y = 0.025, yend = 0.005,
           arrow = arrow(
             length = unit(0.1, "in"))) +
  annotate(geom = "label",
           x = 81, y = 0.03,
           label = "Surprised to see this!", col = "#00998a") +
  annotate(geom = "segment", 
           x = 81, xend = 81, 
           y = 0.025, yend = 0.005,
           arrow = arrow(
             length = unit(0.1, "in"))) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## A hypothetical sampling distribution

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(60,67)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(67, 79)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(79,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 79, y = 0.105,
           label = "Not surprised to see this!", col = "#00998a") +
  annotate(geom = "segment", 
           x = 78, xend = 76, 
           y = 0.10, yend = 0.085,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## But what about small samples?

Any problem with the previous figure? 

- If we draw a single outlying value, should we be surprised? 
- Not enough for us to reject the null hypothesis! It's just a single value
- So what is the problem with the normal distribution? 
  - It doesn't take into account sample size
- So instead, we'll use the **t-distribution**
  - It has an additional parameter: **degrees of freedom**
  - For our purposes, "degrees of freedom" refers to sample size
  - With a very high number of degrees of freedom, the t-distribution is just like the normal
  - With lower "df", the t-distribution has "fatter tails" $\leadsto$ higher probability of extreme values 

## The t-distribution


```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
library(viridis)
ggplot(data.frame(x = c(-6, 6)), aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                col = viridis(4, option = "magma")[3], size = 1.5) +
  stat_function(fun = dt, args = list(df = 1), 
                col = viridis(3, option = "magma")[1], size = 1.5) +
  stat_function(fun = dt, args = list(df = 4), 
                col = viridis(3, option = "magma")[2], size = 1.5) +
  annotate(geom = "label",
           x = 3, y = 0.35,
           label = "Normal distribution", col = viridis(4, option = "magma")[3],
           size = 5) +
  annotate(geom = "label",
           x = 3, y = 0.32,
           label = "t (df = 4)", col = viridis(3, option = "magma")[2],
           size = 5) +
  annotate(geom = "label",
           x = 3, y = 0.29,
           label = "t (df = 1)", col = viridis(3, option = "magma")[1],
           size = 5) +
  theme_custom() +
  labs(x = "Standard deviations away from the mean",
       y = "Density")
```

## p-values

I now "know" what the sampling distribution *would look like* under the null:

  - I know where it peaks (at the null hypothesis, e.g. $H_0$: $\mu=73$)
  - I "know" its standard deviation by estimating the standard error
    - $SE = \dfrac{\hat{\sigma}}{\sqrt{n}}$
  - I know the "degrees of freedom" parameter (the sample size)

The next step: how likely is the data I observe, if the null is true?

- If $\mu_{\text{true}} = 73$, I'm not surprised to draw a sample with mean - 73
- At some point, the data I observe is so unlikely to have been produced by sampling from a population with $\mu_{\text{true}} = 73$ that I must reject the null

## p-values

- Even if I draw a sample that's far from $H_0$, it's possible I drew a weird sample by chance
- e.g. it is possible to draw 20 random students with $\mu_{\text{grade}} = 62$ even if the true mean is 73
- But there is a point where it's so unlikely that I'm comfortable rejecting the null
  - This is our prespecified **significance level** (often $\alpha = 0.05$)
- When looking at our data, we can compute a **p-value**
  - The p-value is a number between 0 and 1
  - It represents the expected probability of observing the sample data, if the null hypothesis were true
  - p-value close to 1: given the null, we're not surprised to see this $\leadsto$ fail to reject the null 
  - p-value close to 0: given the null, we're surprised to see this $\leadsto$ reject the null 
  - $p < \alpha$: reject the null; $p > alpha$: fail to reject the null
  
## Interpreting p-values

Let's say I randomly sample students and compute a mean grade of 67

- $H_0$: $\mu_{\text{true}} = 73$
- Let's say I get a p-value of 0.13; what I can say:
  - If I were to repeatedly sample from our population (students who took the midterm)...
  - I would expect to get a result as "extreme" as this (extreme = far away from the null hypothesis)...
  - In about 13% of repeated samples...
  - If the null hypothesis is true
- In other words: it's somewhat unlikely, but very much possible
- With $\alpha = 0.05$, we fail to reject the null that the mean is 73
  - Can we conclude that the mean is 73? 
    - NO! We do NOT "accept" the null; we "fail to reject"
  - There is no **statistically significant** difference between our sample mean and the null hypothesis 

## p = 0.4 (with non-directional hypothesis)

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(60, 73-qnorm(0.80)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(73-qnorm(0.80)*3, 73+qnorm(0.80)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(73+qnorm(0.80)*3,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_vline(aes(xintercept = 73-qnorm(0.80)*3), 
             linetype = "dashed", size = 1) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  geom_label(aes(x = 73-qnorm(0.80)*3-2.2, y = 0.11), 
             label = expression(mu[sample]*"=70.48"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 80, y = 0.095,
           label = "20% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 79, xend = 77, 
           y = 0.09, yend = 0.065,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  annotate(geom = "label",
           x = 66, y = 0.095,
           label = "20% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 67, xend = 69, 
           y = 0.09, yend = 0.065,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## p = 0.2 (with non-directional hypothesis)

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(60, 73-qnorm(0.90)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(73-qnorm(0.90)*3, 73+qnorm(0.90)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(73+qnorm(0.90)*3,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_vline(aes(xintercept = 73-qnorm(0.9)*3), 
             linetype = "dashed", size = 1) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  geom_label(aes(x = 73-qnorm(0.90)*3-2.2, y = 0.11), 
             label = expression(mu[sample]*"=69.16"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 81, y = 0.055,
           label = "10% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 81, xend = 79, 
           y = 0.05, yend = 0.025,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  annotate(geom = "label",
           x = 64, y = 0.055,
           label = "10% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 65, xend = 67, 
           y = 0.05, yend = 0.025,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## p = 0.1 (with non-directional hypothesis)

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(60, 73-qnorm(0.95)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(73-qnorm(0.95)*3, 73+qnorm(0.95)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(73+qnorm(0.95)*3,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_vline(aes(xintercept = 73-qnorm(0.95)*3), 
             linetype = "dashed", size = 1) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  geom_label(aes(x = 73-qnorm(0.95)*3-2.2, y = 0.11), 
             label = expression(mu[sample]*"=68.07"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 81, y = 0.055,
           label = "5% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 81, xend = 79, 
           y = 0.05, yend = 0.025,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  annotate(geom = "label",
           x = 64, y = 0.055,
           label = "5% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 65, xend = 67, 
           y = 0.05, yend = 0.025,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## p = 0.05 (with non-directional hypothesis)

```{r,echo=FALSE,out.width='100%',fig.width=10,fig.height=7}
ggplot(NULL, aes(c(60,86))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(60, 73-qnorm(0.975)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "grey80", xlim = c(73-qnorm(0.975)*3, 73+qnorm(0.975)*3)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = 73, sd = 3),
            fill = "#00998a", xlim = c(73+qnorm(0.975)*3,86)) +
  geom_vline(aes(xintercept = 73), linetype = "dashed", size = 2) +
  geom_vline(aes(xintercept = 73-qnorm(0.975)*3), 
             linetype = "dashed", size = 1) +
  geom_label(aes(x = 74.5, y = 0.03), label = expression(H[0]*":"*mu*"=73"), 
             size = 5, parse = T) +
  geom_label(aes(x = 73-qnorm(0.975)*3-2.2, y = 0.11), 
             label = expression(mu[sample]*"=67.12"), 
             size = 5, parse = T) +
  annotate(geom = "label",
           x = 81, y = 0.035,
           label = "2.5% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 82, xend = 80, 
           y = 0.03, yend = 0.01,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  annotate(geom = "label",
           x = 64, y = 0.035,
           label = "2.5% of repeated sample means", col = "#00998a") +
  annotate(geom = "segment", 
           x = 64, xend = 66, 
           y = 0.03, yend = 0.01,
           arrow = arrow(
             length = unit(0.1, "in")),
           size = 1.5) +
  theme_custom() +
  labs(x = "Sample mean for the midterm",
       y = "Density")
```

## One-sample t-test in R

\scriptsize

```{r}
# the hypothetical grades I gave you earlier
grades <- c(63, 67, 71, 56, 77, 47)
t.test(grades, mu = 73)
```
\normalsize

Interpret the confidence interval and the p-value

- Should you call me a liar? 

## When should you have called me a liar?

```{r,echo=FALSE}
hyp_grades$p_value <- NA_real_
for(i in 2:nrow(hyp_grades)){
  hyp_grades[i,3] <- t.test(hyp_grades$Grade[1:i], mu = 73)$"p.value" %>% round(3)
}
kbl(hyp_grades[1:7,],
    booktabs = TRUE, 
    caption = "Grades of students you meet in lab") %>% 
  row_spec(7, color = "red")
```

You can call me a liar when you get the 7th data point!

- (Assuming $\alpha = 0.05$)

## Type I and Type II errors

When $p$ is very small, we're very surprised by the data we're seeing

- But weird samples happen! 
- It's not *impossible* that the null *is* true given the data; it's just very unlikely 

Take the example above 

- If 100 of you talk to peers and ask about their midterm grade
- Each person sets $\alpha = 0.05$
- 5 people will accuse me of lying *even if the true mean is 73*
  - i.e. they will draw data that is inconsistent with what I said, even if what I said is true
- This is **Type I error**: I reject the null when the null is actually true
  - Also known as a **false positive**
  - By setting a lower $\alpha$, I reduce the chances of Type I errors
  
## Type I and Type II errors

**Type II error** is the opposite

- You fail to reject the null when the null is actually not true
- Also known as a **false negative**
- By setting a lower $\alpha$, you *increase* the chances of Type II error

\centering

![](pregnant_error.png){height='70%'}

## Differences-in-means

I just presented an example of one hypothesis test where we examined the mean of a variable against some null hypothesis

- Hypothesis tests can be conducted for many different hypotheses
- Another important application: differences-in-means
- Remember what we did in assignment 2 (causality)?

\scriptsize

```{r}
druckman <- read_csv("lectures/lecture_11.1/druckman_2003.csv")
druckman %>% 
  group_by(tv) %>% 
  summarise(who_won = mean(won2,na.rm = T) %>% round(3))
```

## The setup

Again, we have a null hypothesis; what is it? \pause

- $H_0$: $\mu_1 = \mu_2$ \pause

And we have an alternative hypothesis: $H_1$: $\mu_1 \neq \mu_2$

If the null is true, what do we expect to see? 

- If we draw many repeated samples...
- And compute the difference-in-means for each...
- The sampling distribution should be centered on 0

And again, depending on how surprising the data is given the null, we decide to reject the null or fail to reject it

## The difference-in-means in R

\scriptsize

```{r}
t.test(druckman$won2[druckman$tv==0], druckman$won2[druckman$tv==1])
```

\normalsize 

The difference-in-means is different from 0 in a **statistically significant** manner

## The difference-in-means in R

\scriptsize

```{r}
# equivalent to the above
t.test(druckman$won2 ~ druckman$tv) # mu = 0 is the default
```

## How to interpret the difference-in-means

Are differences-in-means causal quantities?

- Well, it depends!
- If they're means from experimental conditions $\leadsto$ causal interpretation
- If not, it's probably hard to interpret them causally
- But they're still interesting!

## The dangers of hypothesis testing

Null hypothesis statistical testing is, by far, the dominant approach

- But it is easy to misinterpret what our statistical tests are saying
- Much discussion recently in the scientific community!

## Political Analysis 

![](pa_pvalues.png)

## "p-hacking"

We've seen that there a (completely arbitrary) threshold below which results are considered "statistically significant"

- Publication is much easier if you achieve statisticaly significance
- Incentive: play around with data until you achieve p < 0.05
  - Play around: add/remove control variables, remove observations, use alternative measures...
- Called: p-hacking, researcher degrees of freedom, garden of forking paths...
- This is a **widespread** problem that we are just starting to grapple with 
- But when you think about it...
  - Are you really more certain of your result if p = 0.049 compared to p = 0.051? 
  
## Wrong side of the arbitrary threshold

::: columns

:::: column

![](pvalue_disappointment1.png)

::::

:::: column

![](pvalue_disappointment2.png)

::::

:::
  
## Jelly beans and acne

![](phacking_xkcd.png)

## Significance 

\centering

![](significance_xkcd.png){height=90%}

## Significance as a dummy

Your results are either statistically significant or they're not

- If p = 0.06 and you set $\alpha = 0.05$, your finding is not statistically significant
  - What should we do? More research! 
  - Hopefully with a larger sample that will be able to detect an effect
  
You will often see papers that ignore this because they want significant results (remember publication bias?)

- "approaches significance", "marginally significant"...
- For a longer (and hilarious) list, [see here](https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/)
\footnotesize
- "As well as being statistically flawed (results are either significant or not and can’t be qualified), the wording is linguistically interesting, often describing an aspect of the result that just doesn’t exist. For example, “a trend towards significance” expresses non-significance as some sort of motion towards significance, which it isn’t: there is no ‘trend’, in any direction, and nowhere for the trend to be ‘towards’."

## Statistical vs substantive significance

Above all, **we may not care about a statistically significant finding**

Statistical significance $\neq$ substantive significance

It is possible to have a statistically significant difference that is substantively not meaningful 

- e.g. a large survey (60,000) shows that mean happiness for Facebook users is 7.64 on 1-10 scale and 7.68 for non-Facebook users
- Given the sample size, we may find a *statistically* significant different difference, e.g. $p < 0.01$
- But do we actually care?
  - **Substantive** significance: does it pass the "so what" test? 

## Why should I care?

Real-world decisions and our understanding of the world depend on our interpretation of ours results

- And our interpretation depends on whether we have statistical significance 

![](colchicine.png)

## Why should I care?

![](colchine_results.png)




## References {.allowframebreaks}

\footnotesize